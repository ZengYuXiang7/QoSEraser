{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class a:\n",
    "    def __init__(self):\n",
    "        self.node2vec_dim = 128\n",
    "        self.node2vec_length = 20\n",
    "        self.node2vec_walk = 50\n",
    "        self.node2vec_epochs = 20\n",
    "        self.node2vec_batchsize = 32\n",
    "        self.node2vec_windows = 3\n",
    "        self.slices = 10\n",
    "        self.interaction = 'NeuCF'\n",
    "        self.devices = 'cpu'\n",
    "        self.dataset = 'rt'\n",
    "        self.path = './datasets/data/WSDREAM/'\n",
    "        self.dimension = 64\n",
    "        self.num_layers = 2\n",
    "        self.dropout = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.dataset import load_data\n",
    "from models.eraser import TensorEraser\n",
    "args = a()\n",
    "df = load_data(args)\n",
    "model = TensorEraser(339, 5825, df, args)\n",
    "f = 'pretrain/models_checkpoints/rt_slices_10_round_1_density_0.1_model_parameter.pkl'\n",
    "model.load_state_dict(t.load(f, map_location='cpu'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorEraser(\n  (sliceUserEmbeddings): ModuleList(\n    (0): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (1): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (2): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (3): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (4): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (5): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (6): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (7): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (8): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n    (9): User_embeds(\n      (embed_user_GMF): Embedding(339, 64)\n      (embed_user_MLP): Embedding(339, 128)\n    )\n  )\n  (sliceItemEmbeddings): ModuleList(\n    (0): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (1): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (2): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (3): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (4): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (5): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (6): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (7): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (8): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n    (9): Item_embeds_NeuCF(\n      (embed_item_GMF): Embedding(5825, 64)\n      (embed_item_MLP): Embedding(5825, 128)\n    )\n  )\n  (slicedInterFunction): ModuleList(\n    (0): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (1): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (2): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (3): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (4): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (5): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (6): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (7): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (8): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n    (9): NeuCF(\n      (MLP_layers): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=256, out_features=128, bias=True)\n        (2): ReLU()\n        (3): Dropout(p=0.1, inplace=False)\n        (4): Linear(in_features=128, out_features=64, bias=True)\n        (5): ReLU()\n      )\n      (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n    )\n  )\n  (user_aggregator_1): UserAggregator(\n    (score): Sequential(\n      (0): Linear(in_features=64, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=1, bias=True)\n    )\n  )\n  (item_aggregator_1): ItemAggregator(\n    (score): Sequential(\n      (0): Linear(in_features=64, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=1, bias=True)\n    )\n  )\n  (user_aggregator_2): UserAggregator(\n    (score): Sequential(\n      (0): Linear(in_features=128, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=1, bias=True)\n    )\n  )\n  (item_aggregator_2): ItemAggregator(\n    (score): Sequential(\n      (0): Linear(in_features=128, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=1, bias=True)\n    )\n  )\n  (global_interaction): NeuCF(\n    (MLP_layers): Sequential(\n      (0): Dropout(p=0.1, inplace=False)\n      (1): Linear(in_features=256, out_features=128, bias=True)\n      (2): ReLU()\n      (3): Dropout(p=0.1, inplace=False)\n      (4): Linear(in_features=128, out_features=64, bias=True)\n      (5): ReLU()\n    )\n    (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "collections.OrderedDict"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t.load(f, map_location='cpu'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-3.1187e-03,  4.6556e-03, -3.2872e-03, -1.8656e-04, -1.8549e-03,\n          2.7473e-03,  3.6567e-03, -1.2986e-03,  5.7415e-04,  3.6378e-03,\n          4.4325e-04, -1.6330e-03,  3.0004e-03,  2.3736e-03, -2.8342e-04,\n         -1.9876e-03,  1.4459e-03, -6.8892e-04,  2.7544e-03, -6.6939e-03,\n         -6.9532e-04, -1.5589e-03, -2.7535e-03,  1.6468e-03,  1.2205e-06,\n          1.5957e-03, -5.0610e-03,  1.4536e-03, -1.8871e-03,  2.2479e-03,\n          4.7273e-05, -4.4776e-03, -8.5562e-05,  2.8122e-03,  1.1843e-04,\n          7.0370e-04, -6.6902e-03,  2.4821e-03,  3.8936e-03, -8.5126e-04,\n         -2.9552e-04, -4.4304e-03,  3.1154e-03, -1.6067e-03,  3.4239e-04,\n         -2.9048e-03, -2.7332e-04,  1.8753e-03,  4.5635e-03,  2.6695e-04,\n         -1.5697e-05, -1.3456e-05,  2.3302e-03,  1.0130e-03,  8.9191e-04,\n          5.8580e-03,  2.3969e-03, -2.2050e-03, -4.2871e-04, -6.4380e-03,\n         -4.1053e-03, -5.7714e-03, -1.9381e-03,  2.3226e-03,  1.3377e-02,\n          5.4351e-02,  6.7054e-02,  1.2468e-03,  1.0042e-02, -1.1967e-02,\n          2.3958e-02, -4.8736e-03,  1.2078e-02, -5.4014e-03, -1.4793e-02,\n          9.6723e-02,  1.0322e-01,  2.5079e-02,  1.4503e-02, -3.6629e-04,\n         -3.6829e-03,  7.4451e-02,  2.1977e-02,  2.6511e-03,  6.3627e-02,\n         -7.3130e-03,  3.1045e-03, -8.7572e-03,  1.7955e-02,  2.8666e-02,\n          6.1386e-02,  1.6839e-02,  1.2784e-03, -1.4279e-03,  3.7242e-02,\n         -7.4606e-03,  7.0225e-03, -4.4120e-02,  6.7148e-03, -1.8310e-02,\n          1.7583e-02,  2.2361e-02,  2.8405e-02, -8.7173e-03,  9.5436e-03,\n          2.6452e-02,  5.1957e-02,  7.2974e-02,  9.8935e-03,  1.4601e-02,\n         -1.7706e-02, -2.6879e-02, -1.2138e-02,  1.2207e-02,  3.1534e-02,\n         -2.1331e-02,  2.5770e-02,  1.8034e-02, -2.2648e-02,  8.0335e-03,\n         -4.0330e-03, -1.6308e-02, -2.8726e-02,  2.8486e-03, -1.3890e-02,\n         -1.9004e-03, -2.2689e-02,  2.3135e-02]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.load(f, map_location='cpu')['global_interaction.predict_layer.weight']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(type(parameter))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliceUserEmbeddings.0.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.0.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.1.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.1.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.2.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.2.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.3.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.3.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.4.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.4.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.5.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.5.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.6.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.6.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.7.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.7.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.8.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.8.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceUserEmbeddings.9.embed_user_GMF.weight : torch.Size([339, 64])\n",
      "sliceUserEmbeddings.9.embed_user_MLP.weight : torch.Size([339, 128])\n",
      "sliceItemEmbeddings.0.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.0.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.1.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.1.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.2.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.2.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.3.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.3.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.4.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.4.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.5.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.5.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.6.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.6.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.7.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.7.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.8.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.8.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "sliceItemEmbeddings.9.embed_item_GMF.weight : torch.Size([5825, 64])\n",
      "sliceItemEmbeddings.9.embed_item_MLP.weight : torch.Size([5825, 128])\n",
      "slicedInterFunction.0.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.0.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.0.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.0.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.0.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.0.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.1.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.1.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.1.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.1.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.1.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.1.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.2.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.2.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.2.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.2.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.2.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.2.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.3.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.3.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.3.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.3.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.3.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.3.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.4.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.4.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.4.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.4.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.4.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.4.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.5.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.5.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.5.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.5.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.5.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.5.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.6.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.6.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.6.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.6.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.6.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.6.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.7.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.7.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.7.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.7.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.7.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.7.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.8.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.8.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.8.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.8.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.8.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.8.predict_layer.bias : torch.Size([1])\n",
      "slicedInterFunction.9.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "slicedInterFunction.9.MLP_layers.1.bias : torch.Size([128])\n",
      "slicedInterFunction.9.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "slicedInterFunction.9.MLP_layers.4.bias : torch.Size([64])\n",
      "slicedInterFunction.9.predict_layer.weight : torch.Size([1, 128])\n",
      "slicedInterFunction.9.predict_layer.bias : torch.Size([1])\n",
      "user_aggregator_1.score.0.weight : torch.Size([32, 64])\n",
      "user_aggregator_1.score.0.bias : torch.Size([32])\n",
      "user_aggregator_1.score.2.weight : torch.Size([1, 32])\n",
      "user_aggregator_1.score.2.bias : torch.Size([1])\n",
      "item_aggregator_1.score.0.weight : torch.Size([32, 64])\n",
      "item_aggregator_1.score.0.bias : torch.Size([32])\n",
      "item_aggregator_1.score.2.weight : torch.Size([1, 32])\n",
      "item_aggregator_1.score.2.bias : torch.Size([1])\n",
      "user_aggregator_2.score.0.weight : torch.Size([64, 128])\n",
      "user_aggregator_2.score.0.bias : torch.Size([64])\n",
      "user_aggregator_2.score.2.weight : torch.Size([1, 64])\n",
      "user_aggregator_2.score.2.bias : torch.Size([1])\n",
      "item_aggregator_2.score.0.weight : torch.Size([64, 128])\n",
      "item_aggregator_2.score.0.bias : torch.Size([64])\n",
      "item_aggregator_2.score.2.weight : torch.Size([1, 64])\n",
      "item_aggregator_2.score.2.bias : torch.Size([1])\n",
      "global_interaction.MLP_layers.1.weight : torch.Size([128, 256])\n",
      "global_interaction.MLP_layers.1.bias : torch.Size([128])\n",
      "global_interaction.MLP_layers.4.weight : torch.Size([64, 128])\n",
      "global_interaction.MLP_layers.4.bias : torch.Size([64])\n",
      "global_interaction.predict_layer.weight : torch.Size([1, 128])\n",
      "global_interaction.predict_layer.bias : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, parameters in model.named_parameters():\n",
    "    print(name, ':', parameters.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "param = [[] for _ in range(args.slices)]\n",
    "for i in range(args.slices):\n",
    "    for name, parameters in model.sliceUserEmbeddings[i].named_parameters():\n",
    "        param[i].append([name, parameters])\n",
    "    for name, parameters in model.sliceItemEmbeddings[i].named_parameters():\n",
    "        param[i].append([name, parameters])\n",
    "    for name, parameters in model.slicedInterFunction[i].named_parameters():\n",
    "        param[i].append([name, parameters])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 embed_user_GMF.weight torch.Size([339, 64])\n",
      "0 embed_user_MLP.weight torch.Size([339, 128])\n",
      "0 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "0 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "0 MLP_layers.1.weight torch.Size([128, 256])\n",
      "0 MLP_layers.1.bias torch.Size([128])\n",
      "0 MLP_layers.4.weight torch.Size([64, 128])\n",
      "0 MLP_layers.4.bias torch.Size([64])\n",
      "0 predict_layer.weight torch.Size([1, 128])\n",
      "0 predict_layer.bias torch.Size([1])\n",
      "1 embed_user_GMF.weight torch.Size([339, 64])\n",
      "1 embed_user_MLP.weight torch.Size([339, 128])\n",
      "1 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "1 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "1 MLP_layers.1.weight torch.Size([128, 256])\n",
      "1 MLP_layers.1.bias torch.Size([128])\n",
      "1 MLP_layers.4.weight torch.Size([64, 128])\n",
      "1 MLP_layers.4.bias torch.Size([64])\n",
      "1 predict_layer.weight torch.Size([1, 128])\n",
      "1 predict_layer.bias torch.Size([1])\n",
      "2 embed_user_GMF.weight torch.Size([339, 64])\n",
      "2 embed_user_MLP.weight torch.Size([339, 128])\n",
      "2 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "2 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "2 MLP_layers.1.weight torch.Size([128, 256])\n",
      "2 MLP_layers.1.bias torch.Size([128])\n",
      "2 MLP_layers.4.weight torch.Size([64, 128])\n",
      "2 MLP_layers.4.bias torch.Size([64])\n",
      "2 predict_layer.weight torch.Size([1, 128])\n",
      "2 predict_layer.bias torch.Size([1])\n",
      "3 embed_user_GMF.weight torch.Size([339, 64])\n",
      "3 embed_user_MLP.weight torch.Size([339, 128])\n",
      "3 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "3 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "3 MLP_layers.1.weight torch.Size([128, 256])\n",
      "3 MLP_layers.1.bias torch.Size([128])\n",
      "3 MLP_layers.4.weight torch.Size([64, 128])\n",
      "3 MLP_layers.4.bias torch.Size([64])\n",
      "3 predict_layer.weight torch.Size([1, 128])\n",
      "3 predict_layer.bias torch.Size([1])\n",
      "4 embed_user_GMF.weight torch.Size([339, 64])\n",
      "4 embed_user_MLP.weight torch.Size([339, 128])\n",
      "4 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "4 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "4 MLP_layers.1.weight torch.Size([128, 256])\n",
      "4 MLP_layers.1.bias torch.Size([128])\n",
      "4 MLP_layers.4.weight torch.Size([64, 128])\n",
      "4 MLP_layers.4.bias torch.Size([64])\n",
      "4 predict_layer.weight torch.Size([1, 128])\n",
      "4 predict_layer.bias torch.Size([1])\n",
      "5 embed_user_GMF.weight torch.Size([339, 64])\n",
      "5 embed_user_MLP.weight torch.Size([339, 128])\n",
      "5 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "5 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "5 MLP_layers.1.weight torch.Size([128, 256])\n",
      "5 MLP_layers.1.bias torch.Size([128])\n",
      "5 MLP_layers.4.weight torch.Size([64, 128])\n",
      "5 MLP_layers.4.bias torch.Size([64])\n",
      "5 predict_layer.weight torch.Size([1, 128])\n",
      "5 predict_layer.bias torch.Size([1])\n",
      "6 embed_user_GMF.weight torch.Size([339, 64])\n",
      "6 embed_user_MLP.weight torch.Size([339, 128])\n",
      "6 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "6 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "6 MLP_layers.1.weight torch.Size([128, 256])\n",
      "6 MLP_layers.1.bias torch.Size([128])\n",
      "6 MLP_layers.4.weight torch.Size([64, 128])\n",
      "6 MLP_layers.4.bias torch.Size([64])\n",
      "6 predict_layer.weight torch.Size([1, 128])\n",
      "6 predict_layer.bias torch.Size([1])\n",
      "7 embed_user_GMF.weight torch.Size([339, 64])\n",
      "7 embed_user_MLP.weight torch.Size([339, 128])\n",
      "7 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "7 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "7 MLP_layers.1.weight torch.Size([128, 256])\n",
      "7 MLP_layers.1.bias torch.Size([128])\n",
      "7 MLP_layers.4.weight torch.Size([64, 128])\n",
      "7 MLP_layers.4.bias torch.Size([64])\n",
      "7 predict_layer.weight torch.Size([1, 128])\n",
      "7 predict_layer.bias torch.Size([1])\n",
      "8 embed_user_GMF.weight torch.Size([339, 64])\n",
      "8 embed_user_MLP.weight torch.Size([339, 128])\n",
      "8 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "8 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "8 MLP_layers.1.weight torch.Size([128, 256])\n",
      "8 MLP_layers.1.bias torch.Size([128])\n",
      "8 MLP_layers.4.weight torch.Size([64, 128])\n",
      "8 MLP_layers.4.bias torch.Size([64])\n",
      "8 predict_layer.weight torch.Size([1, 128])\n",
      "8 predict_layer.bias torch.Size([1])\n",
      "9 embed_user_GMF.weight torch.Size([339, 64])\n",
      "9 embed_user_MLP.weight torch.Size([339, 128])\n",
      "9 embed_item_GMF.weight torch.Size([5825, 64])\n",
      "9 embed_item_MLP.weight torch.Size([5825, 128])\n",
      "9 MLP_layers.1.weight torch.Size([128, 256])\n",
      "9 MLP_layers.1.bias torch.Size([128])\n",
      "9 MLP_layers.4.weight torch.Size([64, 128])\n",
      "9 MLP_layers.4.bias torch.Size([64])\n",
      "9 predict_layer.weight torch.Size([1, 128])\n",
      "9 predict_layer.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(param)):\n",
    "    for j in param[i]:\n",
    "        print(i, j[0], j[1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(list,\n 'embed_user_MLP.weight',\n 'embed_user_MLP.weight',\n torch.nn.parameter.Parameter)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param[0][1]), param[0][1][0], param[0][1][0], type(param[0][1][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X = t.tensor([])\n",
    "for i in range(len(param)):\n",
    "    for j in range(len(param[i])):\n",
    "        if param[i][j][0] == 'embed_user_GMF.weight':\n",
    "            X = t.cat((X, param[i][j][1].unsqueeze(0)))\n",
    "            # print(X.shape)\n",
    "# X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch\n",
    "import d2l.torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "\n",
    "    def __init__(self, query_size, key_size, value_size, num_hiddens, num_heads, dropout, bias=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.attention = d2l.torch.DotProductAttention(dropout)\n",
    "\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "\n",
    "        # FC\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose_output(X, num_heads):\n",
    "        \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "        X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "        X = X.permute(0, 2, 1, 3)\n",
    "        return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "    def transpose_qkv(self, X, num_heads):\n",
    "        \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "        # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "        # num_hiddens/num_heads)\n",
    "        X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "        # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "        # num_hiddens/num_heads)\n",
    "        X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "        # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "        # num_hiddens/num_heads)\n",
    "        return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens = None):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size * num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = self.transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = self.transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = self.transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # output的形状:(batch_size * num_heads)，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "\n",
    "        return self.W_o(output_concat)\n",
    "\n",
    "\n",
    "# num_hiddens, num_heads = 128, 4\n",
    "# multiHeadAttention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5)\n",
    "#\n",
    "# multiHeadAttention.eval()\n",
    "# batch_size, num_queries = 1, 4\n",
    "# num_kvpairs, valid_lens = 6, torch.tensor([3, 2])\n",
    "#\n",
    "# X = torch.ones(size = (batch_size, num_queries, num_hiddens))\n",
    "# Y = torch.ones(size = (batch_size, num_kvpairs, num_hiddens))\n",
    "#\n",
    "# multiHeadAttention(X, X, X).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_user_GMF.weight 2 torch.Size([339, 64])\n",
      "embed_user_MLP.weight 2 torch.Size([339, 128])\n",
      "聚合模型完毕\n",
      "embed_item_GMF.weight 2 torch.Size([5825, 64])\n",
      "embed_item_MLP.weight 2 torch.Size([5825, 128])\n",
      "聚合模型完毕\n",
      "MLP_layers.1.weight 2 torch.Size([128, 256])\n",
      "MLP_layers.1.bias 1 torch.Size([128])\n",
      "MLP_layers.4.weight 2 torch.Size([64, 128])\n",
      "MLP_layers.4.bias 1 torch.Size([64])\n",
      "predict_layer.weight 2 torch.Size([1, 128])\n",
      "predict_layer.bias 1 torch.Size([1])\n",
      "聚合模型完毕\n"
     ]
    }
   ],
   "source": [
    "from models.interaction import User_embeds, Item_embeds_NeuCF, NeuCF, CSMF\n",
    "\n",
    "\n",
    "def agg_func_param(model, submodel):\n",
    "    param = [[] for _ in range(args.slices)]\n",
    "    for i in range(args.slices):\n",
    "        for name, parameters in model.sliceUserEmbeddings[i].named_parameters():\n",
    "            param[i].append([name, parameters])\n",
    "        for name, parameters in model.sliceItemEmbeddings[i].named_parameters():\n",
    "            param[i].append([name, parameters])\n",
    "        for name, parameters in model.slicedInterFunction[i].named_parameters():\n",
    "            param[i].append([name, parameters])\n",
    "\n",
    "    def agg_subfunc_param(model, submodel, string):\n",
    "        # 获取这个子模型的全部参数\n",
    "        X = t.tensor([])\n",
    "        for i in range(len(param)):\n",
    "            for j in range(len(param[i])):\n",
    "                if param[i][j][0] == string:\n",
    "                    # print(param[i][j][0], len(param[i][j][1].shape))\n",
    "                    if len(param[i][j][1].shape) == 1:\n",
    "                        temp = param[i][j][1].reshape(1, -1)\n",
    "                    # print(temp.shape)\n",
    "                    temp = param[i][j][1].unsqueeze(0)\n",
    "                    X = t.cat((X, temp))\n",
    "\n",
    "        # 定位这个模型，调整attention的hidden size\n",
    "        num_heads = None\n",
    "        for name, parameters in submodel.named_parameters():\n",
    "            if name == string:\n",
    "                dimension = 0\n",
    "                print(name, len(parameters.shape), parameters.shape)\n",
    "                if len(parameters.shape) == 1:\n",
    "                    num_hiddens = 1\n",
    "                else:\n",
    "                    num_hiddens = parameters.shape[1]\n",
    "                break\n",
    "\n",
    "        # print(num_hiddens)\n",
    "        multiHeadAttention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, 1, 0.1)\n",
    "\n",
    "        X = X.reshape(X.shape[0], X.shape[1], -1)\n",
    "        # print(X.shape)\n",
    "        Y = multiHeadAttention(X, X, X)\n",
    "        final_weight = Y.mean(dim = 0)\n",
    "\n",
    "        return final_weight\n",
    "\n",
    "    submodel = submodel\n",
    "    import collections\n",
    "    final_weight = collections.OrderedDict()\n",
    "    all_submodel = []\n",
    "\n",
    "    # 对一个模型的全部子模型聚合\n",
    "    for name, parameter in submodel.named_parameters():\n",
    "        all_submodel.append(name)\n",
    "\n",
    "        temp = agg_subfunc_param(model, submodel, name)\n",
    "\n",
    "        if temp.shape[1] == 1:\n",
    "            temp = temp.reshape(-1)\n",
    "\n",
    "        parameters = t.nn.parameter.Parameter(temp)\n",
    "\n",
    "        final_weight[name] = parameters\n",
    "\n",
    "    submodel.load_state_dict(final_weight)\n",
    "    print('聚合模型完毕')\n",
    "\n",
    "    return submodel\n",
    "\n",
    "def prepare_for_aggregate(model):\n",
    "\n",
    "    user_func = User_embeds(339, args.dimension, args)\n",
    "    item_func = Item_embeds_NeuCF(5825, args.dimension, args)\n",
    "    interaction = NeuCF(339, 5825, args.dimension, args)\n",
    "\n",
    "    user_func = agg_func_param(model, user_func)\n",
    "    item_func = agg_func_param(model, item_func)\n",
    "    interaction = agg_func_param(model, interaction)\n",
    "\n",
    "prepare_for_aggregate(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%de'f\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_layers.1.weight\n",
      "MLP_layers.1.bias\n",
      "MLP_layers.4.weight\n",
      "MLP_layers.4.bias\n",
      "predict_layer.weight\n",
      "predict_layer.bias\n"
     ]
    }
   ],
   "source": [
    "interaction = NeuCF(339, 5825, args.dimension, args)\n",
    "for name, parameters in interaction.named_parameters():\n",
    "    print(name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# interaction = CSMF(339, 5825, args)\n",
    "# for name, parameters in interaction.named_parameters():\n",
    "    # print(name)\n",
    "# interaction = agg_func_param(model, interaction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
