{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "# Author: yuxiang Zeng\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import *\n",
    "from tqdm import *\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, density):\n",
    "        self.density = density\n",
    "        self.dimension = 5\n",
    "        self.batch_size = 128\n",
    "        self.epochs = 50\n",
    "        self.devices = 'gpu'\n",
    "        self.verbose = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def ErrMetrics(realVec, estiVec):\n",
    "    realVec = t.tensor(realVec)\n",
    "    estiVec = t.tensor(estiVec)\n",
    "\n",
    "    absError = t.abs(estiVec - realVec)\n",
    "\n",
    "    MAE = t.mean(absError)\n",
    "\n",
    "    RMSE = t.linalg.norm(absError) / t.sqrt(t.tensor(absError.shape[0]))\n",
    "\n",
    "    NMAE = MAE / (t.sum(realVec) / absError.shape[0])\n",
    "\n",
    "    relativeError = absError / realVec\n",
    "\n",
    "    MRE = t.tensor(np.percentile(relativeError, 50))  # Mean Relative Error\n",
    "    NPRE = t.tensor(np.percentile(relativeError, 90))  #\n",
    "\n",
    "    return MAE, RMSE, NMAE, MRE, NPRE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "class Basic_SVD(Module):\n",
    "    def __init__(self, dimension):\n",
    "        super().__init__()\n",
    "        self.user_embed = t.nn.Embedding(339, dimension)\n",
    "        self.item_embed = t.nn.Embedding(5825, dimension)\n",
    "        self.activation = t.nn.ReLU()\n",
    "        self.pred_layer = t.nn.Linear(dimension, 1)\n",
    "\n",
    "    def forward(self, userIdx, itemIdx):\n",
    "        user_embeds = self.user_embed(userIdx)\n",
    "        item_embeds = self.item_embed(itemIdx)\n",
    "\n",
    "        # prediction = self.activation(self.pred_layer(user_embeds * item_embeds))\n",
    "        prediction = self.pred_layer(user_embeds * item_embeds)\n",
    "\n",
    "        prediction[prediction < 0] = 0\n",
    "        return prediction.flatten(), user_embeds, item_embeds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def test_train_split(tensor, args):\n",
    "    quantile = np.percentile(tensor, q=100)\n",
    "    tensor[tensor > quantile] = 0\n",
    "    tensor /= quantile\n",
    "    density = args.density\n",
    "\n",
    "    mask = np.random.rand(*tensor.shape).astype('float32')  # [0, 1]\n",
    "\n",
    "    mask[mask > density] = 1\n",
    "    mask[mask < density] = 0\n",
    "\n",
    "    train_Tensor = tensor * (1 - mask)\n",
    "\n",
    "    size = int(0.05 * np.prod(tensor.shape))\n",
    "\n",
    "    trIdx, tcIdx = mask.nonzero()\n",
    "    p = np.random.permutation(len(trIdx))\n",
    "    trIdx, tcIdx = trIdx[p], tcIdx[p]\n",
    "\n",
    "    vrIdx, vcIdx = trIdx[:size], tcIdx[:size]\n",
    "    trIdx, tcIdx = trIdx[size:], tcIdx[size:]\n",
    "\n",
    "    valid_Tensor = np.zeros_like(tensor)\n",
    "    test_Tensor = np.zeros_like(tensor)\n",
    "\n",
    "    valid_Tensor[vrIdx, vcIdx] = tensor[vrIdx, vcIdx]\n",
    "\n",
    "    test_Tensor[trIdx, tcIdx] = tensor[trIdx, tcIdx]\n",
    "\n",
    "    return train_Tensor, valid_Tensor, test_Tensor, quantile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "class QoSdataset(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        output = self.idx[index]\n",
    "        userIdx, itemIdx, value = t.as_tensor(output[0]).long(), t.as_tensor(output[1]).long(), output[2]\n",
    "        return userIdx, itemIdx, value\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = np.array(data)\n",
    "        self.idx = self.get_index(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_index(data):\n",
    "        userIdx, itemIdx = data.nonzero()\n",
    "        value = []\n",
    "        for i in trange(len(userIdx)):\n",
    "            value.append(data[userIdx[i], itemIdx[i]])\n",
    "        index = np.transpose([userIdx, itemIdx, np.array(value)])\n",
    "        return t.tensor(index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def get_dataloader(train_set, valid_set, test_set):\n",
    "    agg = False\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=0 if not agg else 4,\n",
    "        prefetch_factor=2 if not agg else 2\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_set,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=0 if not agg else 4,\n",
    "        prefetch_factor=2 if not agg else 2\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=False,  # 测试集没必要打乱\n",
    "        pin_memory=True,\n",
    "        num_workers=0 if not agg == 'Windows' else 8,\n",
    "        prefetch_factor=2 if not agg == 'Windows' else 4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "from utility.utils import log\n",
    "\n",
    "\n",
    "def train(model, train_loader, valid_loader):\n",
    "    loss_function = t.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-3\n",
    "    optimizer_model = t.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if args.devices == 'gpu':\n",
    "        model = model.cuda()\n",
    "        loss_function = loss_function.cuda()\n",
    "\n",
    "    validBestMAE, validBestRMSE, validBestNMAE, validBestMRE, validBestNPRE = 1e5, 1e5, 1e5, 1e5, 1e5\n",
    "\n",
    "    params = None\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        t.set_grad_enabled(True)\n",
    "\n",
    "        for train_Batch in train_loader:\n",
    "            userIdx, itemIdx, mVal = train_Batch\n",
    "            if args.devices == 'gpu':\n",
    "                userIdx, itemIdx, mVal = userIdx.cuda(), itemIdx.cuda(), mVal.cuda()\n",
    "            pred = model.forward(userIdx, itemIdx)\n",
    "            loss = loss_function(pred, mVal)\n",
    "            optimizer_model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_model.step()\n",
    "\n",
    "        # 设定为评估状态\n",
    "        t.set_grad_enabled(False)\n",
    "\n",
    "        reals, preds = [], []\n",
    "        for valid_Batch in valid_loader:\n",
    "            userIdx, itemIdx, mVal = valid_Batch\n",
    "            if args.devices == 'gpu':\n",
    "                userIdx, itemIdx = userIdx.cuda(), itemIdx.cuda()\n",
    "            pred = model.forward(userIdx, itemIdx)\n",
    "            reals += mVal.tolist()\n",
    "            preds += pred.tolist()\n",
    "\n",
    "        reals = np.array(reals)\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        validMAE, validRMSE, validNMAE, validMRE, validNPRE = ErrMetrics(reals * quantile, preds * quantile)\n",
    "\n",
    "        if args.verbose and ((epoch + 1) % args.verbose == 0 or (epoch + 1) == args.epochs):\n",
    "            log(f'Epoch {(epoch + 1):2d} : MAE : {validMAE:5.4f}  RMSE : {validRMSE:5.4f}  NMAE : {validNMAE:5.4f}  MRE : {validMRE:5.4f}  NPRE : {validNPRE:5.4f}')\n",
    "\n",
    "        if validMAE < validBestMAE:\n",
    "            params = model.state_dict()\n",
    "\n",
    "    return params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    reals, preds = [], []\n",
    "    # 开始测试\n",
    "    for testBatch in test_loader:\n",
    "        userIdx, itemIdx, mVal = testBatch\n",
    "        if args.devices == 'gpu':\n",
    "            userIdx, itemIdx = userIdx.cuda(), itemIdx.cuda()\n",
    "        pred = model.forward(userIdx, itemIdx)\n",
    "        reals += mVal.tolist()\n",
    "        preds += pred.tolist()\n",
    "\n",
    "    reals = np.array(reals)\n",
    "    preds = np.array(preds)\n",
    "    testMAE, testRMSE, testNMAE, testMRE, testNPRE = ErrMetrics(reals * quantile , preds * quantile)\n",
    "\n",
    "    log(f'Result : MAE : {testMAE:5.4f}  RMSE : {testRMSE:5.4f}  NMAE : {testNMAE:5.4f}  MRE : {testMRE:5.4f}  NPRE : {testNPRE:5.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "args = Args(0.1)\n",
    "args.verbose = 10\n",
    "args.epochs = 55"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# df = np.array(pk.load(open('./datasets/data/WSDREAM/rt.pk', 'rb')))\n",
    "# train_Tensor, valid_Tensor, test_Tensor, quantile = test_train_split(df, args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# (train_Tensor != 0).sum(), (valid_Tensor != 0).sum(), (test_Tensor != 0).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# train_set = QoSdataset(train_Tensor)\n",
    "# valid_set = QoSdataset(valid_Tensor)\n",
    "# test_set = QoSdataset(test_Tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# net = Basic_SVD(args.dimension)\n",
    "# train_loader, valid_loader, test_loader = get_dataloader(train_set, valid_set, test_set)\n",
    "# params = train(net, train_loader, valid_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# net.load_state_dict(params)\n",
    "# test(net, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# SISA2\n",
    "def random_split_to_shard2(tensor, args):\n",
    "    split_Tensor = []\n",
    "    # print('456')\n",
    "\n",
    "    train_Tensor = tensor\n",
    "\n",
    "    idx = np.arange(339, dtype='int64')\n",
    "    p = np.random.permutation(len(idx))\n",
    "    idx = idx[p]\n",
    "\n",
    "    size = int(339 * 0.1)\n",
    "    idx = idx[:size]\n",
    "\n",
    "    train_Tensor = np.zeros_like(tensor)\n",
    "    train_Tensor[idx] = tensor[idx]\n",
    "    return train_Tensor, idx\n",
    "\n",
    "def learn(model, train_loader, valid_loader):\n",
    "    loss_function = t.nn.L1Loss()\n",
    "    # args.epochs = 1\n",
    "    learning_rate = 1e-3\n",
    "    optimizer_model = t.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.cuda()\n",
    "    loss_function = loss_function.cuda()\n",
    "    for epoch in range(args.epochs):\n",
    "        t.set_grad_enabled(True)\n",
    "        for train_Batch in train_loader:\n",
    "            userIdx, itemIdx, mVal = train_Batch\n",
    "            userIdx, itemIdx, mVal = userIdx.cuda(), itemIdx.cuda(), mVal.cuda()\n",
    "            pred, user_embedding, item_embedding = model.forward(userIdx, itemIdx)\n",
    "            loss = loss_function(pred, mVal)\n",
    "            optimizer_model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_model.step()\n",
    "\n",
    "        # 设定为评估状态\n",
    "        t.set_grad_enabled(False)\n",
    "\n",
    "    return user_embedding, item_embedding, model.state_dict()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192225/192225 [00:00<00:00, 3258036.84it/s]\n",
      "100%|██████████| 98733/98733 [00:00<00:00, 2903918.61it/s]\n",
      "100%|██████████| 1678360/1678360 [00:00<00:00, 3421495.29it/s]\n"
     ]
    }
   ],
   "source": [
    "df = np.array(pk.load(open('./datasets/data/WSDREAM/rt.pk', 'rb')))\n",
    "train_Tensor, valid_Tensor, test_Tensor, quantile = test_train_split(df, args)\n",
    "train_Tensor, idx = random_split_to_shard2(df, args)\n",
    "args.batch_size = 192225\n",
    "train_set = QoSdataset(train_Tensor)\n",
    "valid_set = QoSdataset(valid_Tensor)\n",
    "test_set = QoSdataset(test_Tensor)\n",
    "net = Basic_SVD(args.dimension)\n",
    "train_loader, valid_loader, test_loader = get_dataloader(train_set, valid_set, test_set)\n",
    "args.epochs = 1\n",
    "user_embedding, item_embedding, _ = learn(net, train_loader, valid_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([192225, 3])"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.idx.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 8 13 31 45 51 54 62 77 90 95 103 104 107 112 157 158 166 167 200 209 211 222 228 239 244 272 277 280 296 318 327 "
     ]
    }
   ],
   "source": [
    "idx = sorted(idx)\n",
    "for i in idx:\n",
    "    print(i, end=' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[36.3289],\n        [-3.2075],\n        [14.4693],\n        ...,\n        [-3.9652],\n        [-2.5721],\n        [ 7.3932]], device='cuda:0')"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = t.nn.Linear(args.dimension, 1).cuda()\n",
    "y = f(user_embedding * item_embedding)\n",
    "y * 19.9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "((192225, 5), (192225, 5))"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding.cpu().numpy().shape, item_embedding.cpu().numpy().shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.8154032 , -0.8046755 ,  0.5940565 ,  0.52667314, -0.12243475],\n       [-1.8154032 , -0.8046755 ,  0.5940565 ,  0.52667314, -0.12243475],\n       [-1.8154032 , -0.8046755 ,  0.5940565 ,  0.52667314, -0.12243475],\n       ...,\n       [ 0.22662273, -2.4708698 ,  0.9294187 ,  0.4272715 , -0.46499878],\n       [ 0.22662273, -2.4708698 ,  0.9294187 ,  0.4272715 , -0.46499878],\n       [ 0.22662273, -2.4708698 ,  0.9294187 ,  0.4272715 , -0.46499878]],\n      dtype=float32)"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding.cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.647503  ,  0.32394072, -0.39682087, -0.6036693 , -0.7839168 ],\n       [-0.632833  , -1.1172096 ,  0.68209636, -0.02556576, -0.07542175],\n       [ 0.67464656, -0.8494805 ,  1.091489  , -1.7129805 , -0.20339127],\n       ...,\n       [ 1.4186572 , -0.3099547 , -0.18475732,  0.54770195,  0.89754623],\n       [ 0.6377097 ,  0.32385835, -0.23696978,  2.012862  ,  0.3786234 ],\n       [-0.5017906 ,  0.07678311,  1.1613884 ,  0.14551407,  0.26140904]],\n      dtype=float32)"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embedding.cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-4.8063, -0.2607, -0.2357, -0.3179,  0.0960],\n        [ 1.1488,  0.8990,  0.4052, -0.0135,  0.0092],\n        [-1.2248,  0.6836,  0.6484, -0.9022,  0.0249],\n        ...,\n        [ 0.3215,  0.7659, -0.1717,  0.2340, -0.4174],\n        [ 0.1445, -0.8002, -0.2202,  0.8600, -0.1761],\n        [-0.1137, -0.1897,  1.0794,  0.0622, -0.1216]], device='cuda:0')"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding * item_embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embed.weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.5765, -0.2418, -0.5091,  0.8081, -0.3201],\n",
      "        [-1.8144, -0.8037,  0.5931,  0.5257, -0.1234],\n",
      "        [ 0.6296, -0.8731, -1.1572,  0.0776,  0.7717],\n",
      "        ...,\n",
      "        [-0.2629, -0.8242,  0.2592, -0.8079,  1.5144],\n",
      "        [ 1.4680, -1.2757, -0.2142, -2.7597,  0.3174],\n",
      "        [-0.5477,  0.5541,  0.7850, -0.6887, -1.3640]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([339, 5])\n",
      "--------------------------------------------------------------------------------\n",
      "item_embed.weight\n",
      "Parameter containing:\n",
      "tensor([[ 2.6465,  0.3229, -0.3958, -0.6047, -0.7849],\n",
      "        [-0.6318, -1.1162,  0.6811, -0.0246, -0.0745],\n",
      "        [ 0.6736, -0.8501,  1.0905, -1.7120, -0.2025],\n",
      "        ...,\n",
      "        [ 1.4177, -0.3110, -0.1838,  0.5467,  0.8966],\n",
      "        [ 0.6367,  0.3229, -0.2360,  2.0119,  0.3776],\n",
      "        [-0.5008,  0.0758,  1.1604,  0.1465,  0.2604]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([5825, 5])\n",
      "--------------------------------------------------------------------------------\n",
      "pred_layer.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.3622, -0.2100,  0.2536, -0.1885,  0.0386]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([1, 5])\n",
      "--------------------------------------------------------------------------------\n",
      "pred_layer.bias\n",
      "Parameter containing:\n",
      "tensor([0.1020], device='cuda:0', requires_grad=True)\n",
      "torch.Size([1])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temp = None\n",
    "for name, parameter in net.named_parameters():\n",
    "    print(name)\n",
    "    print(parameter)\n",
    "    print(parameter.shape)\n",
    "    print('-' * 80)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.5765132 , -0.24181476, -0.5090597 ,  0.80809194, -0.32008168],\n       [-1.8144032 , -0.80367553,  0.5930565 ,  0.52567315, -0.12343416],\n       [ 0.6296369 , -0.87307435, -1.1572306 ,  0.07763115,  0.77166176],\n       ...,\n       [-0.262866  , -0.82421356,  0.25917768, -0.8078682 ,  1.5144199 ],\n       [ 1.4680147 , -1.2757335 , -0.21419285, -2.7596633 ,  0.3173996 ],\n       [-0.54773873,  0.5540975 ,  0.78499675, -0.68874353, -1.3639877 ]],\n      dtype=float32)"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['user_embed.weight'].cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# net.state_dict()['item_embed.weight'].cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  1,   5,   8,  13,  31,  45,  51,  54,  62,  77,  90,  95, 103,\n       104, 107, 112, 157, 158, 166, 167, 200, 209, 211, 222, 228, 239,\n       244, 272, 277, 280, 296, 318, 327], dtype=int64)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "trained = []\n",
    "non_trained = []\n",
    "arr = net.state_dict()['user_embed.weight'].cpu().numpy()\n",
    "for i in range(len(arr)):\n",
    "    if i in idx:\n",
    "        trained.append(arr[i].tolist())\n",
    "    else:\n",
    "        non_trained.append(arr[i].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.81440318, -0.80367553,  0.5930565 ,  0.52567315, -0.12343416],\n       [-0.13140589, -1.42670798,  1.39358091, -0.11256768, -1.67763603],\n       [ 1.75348532,  0.40418062,  1.26916695,  1.28193045,  0.90981156],\n       [ 0.81482798,  0.59471709,  1.26239395,  1.3121177 , -0.82508183],\n       [ 0.09462714,  0.20207307, -0.92027861,  0.39040729,  0.02768595],\n       [-0.32375687, -1.83446753,  0.3009524 , -0.70259476,  0.67990357],\n       [ 1.81397641, -2.15060186, -0.40559715, -0.0374691 , -0.68198574],\n       [ 1.47702444,  0.21240695, -0.96304923,  0.54820305,  1.99177039],\n       [ 0.3561098 , -1.07826507, -1.59564006, -1.29226232,  0.7676031 ],\n       [ 0.67558384,  0.01700601, -0.89007878, -3.24522567,  0.09809425],\n       [ 0.23596637, -0.63896775,  1.19222116, -0.03510421, -0.18140012],\n       [ 0.9647581 , -0.18848954,  0.70268506, -0.90309221, -0.78558004],\n       [ 1.12619054, -1.80314028, -1.33996403, -0.03029682, -0.3700164 ],\n       [ 1.15867579, -0.30095524, -1.09439695,  0.58192122,  1.25959218],\n       [-0.52718729,  0.42459592,  0.60163468,  0.0206314 ,  0.65033132],\n       [ 0.4991523 , -0.13720647,  0.03988848, -1.19482183,  1.81940401],\n       [-0.25572643, -1.27073097, -2.15256548,  1.16452992,  0.31860733],\n       [ 0.79217327,  0.21900706, -0.59926265, -0.42425174, -0.19491503],\n       [-0.38706619, -0.63266671,  0.26974723, -1.48083651,  0.40963537],\n       [ 1.6867435 , -0.35128871, -0.18214518, -1.47979546, -0.66384244],\n       [-1.29265225, -0.40917999,  1.6519289 ,  0.66920215, -0.11496622],\n       [-0.75075793,  0.02650822,  1.37314487, -0.1944074 , -0.45168307],\n       [-0.152943  ,  1.15439451,  1.29343033,  0.14159475,  0.89364815],\n       [-1.71448362, -0.34481323,  0.13365065,  0.984429  ,  0.07256442],\n       [ 0.57776332,  1.26140475, -0.50618738, -0.90640634,  0.02732924],\n       [-0.53213507,  0.12775612, -1.5599885 , -0.07628013,  1.5542568 ],\n       [-1.47462761, -1.39174759, -1.03273284,  0.27657145,  1.99298263],\n       [ 0.06557829, -0.60812074, -1.57450664,  0.63023782,  1.25012636],\n       [ 1.58444738, -1.13227606, -0.51408112,  0.01076366, -0.15279755],\n       [-2.11508489,  1.43531287,  0.46045023,  0.49346238, -0.49791253],\n       [-1.74825823,  0.55051374,  0.75033677, -0.94610584,  0.8061738 ],\n       [-0.40194276,  2.7612288 , -0.40053019,  0.14917359, -0.31897125],\n       [ 0.22562274, -2.46986985,  0.9284187 ,  0.42627153, -0.46400079]])"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trained)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "user_embed = []\n",
    "net = net.cuda()\n",
    "for i in range(339):\n",
    "    user_embed.append(net.user_embed(t.tensor(i).cuda()).cpu().tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 8 13 31 45 51 54 62 77 90 95 103 104 107 112 157 158 166 167 200 209 211 222 228 239 244 272 277 280 296 318 327 "
     ]
    }
   ],
   "source": [
    "for i in idx:\n",
    "    print(i, end=' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.57651317, -0.24181476, -0.50905973,  0.80809194, -0.32008168],\n       [-1.81440318, -0.80367553,  0.5930565 ,  0.52567315, -0.12343416],\n       [ 0.62963688, -0.87307435, -1.15723062,  0.07763115,  0.77166176],\n       ...,\n       [-0.26286599, -0.82421356,  0.25917768, -0.80786818,  1.51441991],\n       [ 1.46801472, -1.27573347, -0.21419285, -2.75966334,  0.31739959],\n       [-0.54773873,  0.55409747,  0.78499675, -0.68874353, -1.36398768]])"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(user_embed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "trained, non_trained = [], []\n",
    "for i in range(len(user_embed)):\n",
    "    if i in idx:\n",
    "        trained.append(user_embed[i])\n",
    "    else:\n",
    "        non_trained.append(user_embed[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.81440318, -0.80367553,  0.5930565 ,  0.52567315, -0.12343416],\n       [-0.13140589, -1.42670798,  1.39358091, -0.11256768, -1.67763603],\n       [ 1.75348532,  0.40418062,  1.26916695,  1.28193045,  0.90981156],\n       [ 0.81482798,  0.59471709,  1.26239395,  1.3121177 , -0.82508183],\n       [ 0.09462714,  0.20207307, -0.92027861,  0.39040729,  0.02768595],\n       [-0.32375687, -1.83446753,  0.3009524 , -0.70259476,  0.67990357],\n       [ 1.81397641, -2.15060186, -0.40559715, -0.0374691 , -0.68198574],\n       [ 1.47702444,  0.21240695, -0.96304923,  0.54820305,  1.99177039],\n       [ 0.3561098 , -1.07826507, -1.59564006, -1.29226232,  0.7676031 ],\n       [ 0.67558384,  0.01700601, -0.89007878, -3.24522567,  0.09809425],\n       [ 0.23596637, -0.63896775,  1.19222116, -0.03510421, -0.18140012],\n       [ 0.9647581 , -0.18848954,  0.70268506, -0.90309221, -0.78558004],\n       [ 1.12619054, -1.80314028, -1.33996403, -0.03029682, -0.3700164 ],\n       [ 1.15867579, -0.30095524, -1.09439695,  0.58192122,  1.25959218],\n       [-0.52718729,  0.42459592,  0.60163468,  0.0206314 ,  0.65033132],\n       [ 0.4991523 , -0.13720647,  0.03988848, -1.19482183,  1.81940401],\n       [-0.25572643, -1.27073097, -2.15256548,  1.16452992,  0.31860733],\n       [ 0.79217327,  0.21900706, -0.59926265, -0.42425174, -0.19491503],\n       [-0.38706619, -0.63266671,  0.26974723, -1.48083651,  0.40963537],\n       [ 1.6867435 , -0.35128871, -0.18214518, -1.47979546, -0.66384244],\n       [-1.29265225, -0.40917999,  1.6519289 ,  0.66920215, -0.11496622],\n       [-0.75075793,  0.02650822,  1.37314487, -0.1944074 , -0.45168307],\n       [-0.152943  ,  1.15439451,  1.29343033,  0.14159475,  0.89364815],\n       [-1.71448362, -0.34481323,  0.13365065,  0.984429  ,  0.07256442],\n       [ 0.57776332,  1.26140475, -0.50618738, -0.90640634,  0.02732924],\n       [-0.53213507,  0.12775612, -1.5599885 , -0.07628013,  1.5542568 ],\n       [-1.47462761, -1.39174759, -1.03273284,  0.27657145,  1.99298263],\n       [ 0.06557829, -0.60812074, -1.57450664,  0.63023782,  1.25012636],\n       [ 1.58444738, -1.13227606, -0.51408112,  0.01076366, -0.15279755],\n       [-2.11508489,  1.43531287,  0.46045023,  0.49346238, -0.49791253],\n       [-1.74825823,  0.55051374,  0.75033677, -0.94610584,  0.8061738 ],\n       [-0.40194276,  2.7612288 , -0.40053019,  0.14917359, -0.31897125],\n       [ 0.22562274, -2.46986985,  0.9284187 ,  0.42627153, -0.46400079]])"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trained)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.57651317, -0.24181476, -0.50905973,  0.80809194, -0.32008168],\n       [ 0.62963688, -0.87307435, -1.15723062,  0.07763115,  0.77166176],\n       [ 0.96675229,  1.15178859,  0.12776124, -0.05298454, -1.41787803],\n       ...,\n       [-0.26286599, -0.82421356,  0.25917768, -0.80786818,  1.51441991],\n       [ 1.46801472, -1.27573347, -0.21419285, -2.75966334,  0.31739959],\n       [-0.54773873,  0.55409747,  0.78499675, -0.68874353, -1.36398768]])"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(non_trained)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp = None\n",
    "for name, parameter in net.named_parameters():\n",
    "    # print(name)\n",
    "    # print(parameter)\n",
    "    # print(parameter.shape)\n",
    "    print('-' * 80)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.81040299, -0.79967558,  0.58905655,  0.5216732 , -0.12743148],\n       [-0.127406  , -1.4227078 ,  1.38958073, -0.10856824, -1.67363679],\n       [ 1.74948514,  0.40018079,  1.26516676,  1.27793074,  0.90581268],\n       [ 0.81082803,  0.59071714,  1.25839376,  1.30811751, -0.82108647],\n       [ 0.09062722,  0.19807318, -0.91627866,  0.38640735,  0.02368835],\n       [-0.31975693, -1.83046734,  0.29695246, -0.69859481,  0.67590463],\n       [ 1.80997622, -2.14660215, -0.40159732, -0.04146788, -0.68597895],\n       [ 1.47302425,  0.20840706, -0.95904928,  0.5442031 ,  1.98777115],\n       [ 0.35210985, -1.07426488, -1.59163988, -1.28826213,  0.76360404],\n       [ 0.67158389,  0.01300665, -0.88607883, -3.24122596,  0.0940977 ],\n       [ 0.23196642, -0.6349678 ,  1.18822098, -0.03910354, -0.18538806],\n       [ 0.96075815, -0.18448985,  0.69868511, -0.89909226, -0.78158206],\n       [ 1.12219036, -1.7991401 , -1.33596385, -0.03429555, -0.37395012],\n       [ 1.1546756 , -0.29695541, -1.09039676,  0.57792127,  1.25559294],\n       [-0.52318734,  0.42059597,  0.59763473,  0.01663237,  0.64633197],\n       [ 0.49515235, -0.13320664,  0.03588871, -1.19082165,  1.8154043 ],\n       [-0.25172648, -1.26673079, -2.14856577,  1.16053021,  0.31460908],\n       [ 0.78817332,  0.21500717, -0.59526271, -0.42025179, -0.19888858],\n       [-0.38306624, -0.62866676,  0.26574728, -1.47683632,  0.40563655],\n       [ 1.68274331, -0.34728888, -0.17814553, -1.47579527, -0.65986437],\n       [-1.28865206, -0.40518016,  1.64792871,  0.6652022 , -0.11896203],\n       [-0.74675798,  0.02250862,  1.36914468, -0.19040763, -0.45566708],\n       [-0.14894311,  1.15039432,  1.28943014,  0.13759498,  0.88964909],\n       [-1.71048343, -0.3408134 ,  0.12965117,  0.98042905,  0.06856631],\n       [ 0.57376337,  1.25740457, -0.50218743, -0.90240639,  0.02333175],\n       [-0.52813512,  0.12375636, -1.55598831, -0.07228132,  1.55025744],\n       [-1.47062743, -1.38774741, -1.02873266,  0.27257162,  1.98898339],\n       [ 0.06157848, -0.60412079, -1.57050645,  0.62623787,  1.24612713],\n       [ 1.5804472 , -1.12827587, -0.51008117,  0.0067641 , -0.156791  ],\n       [-2.11108518,  1.43131268,  0.45645028,  0.48946255, -0.49391857],\n       [-1.74425805,  0.5465138 ,  0.74633682, -0.94210589,  0.80217487],\n       [-0.39794281,  2.75722909, -0.39653024,  0.14517382, -0.32296622],\n       [ 0.22162279, -2.46587014,  0.92441875,  0.4222717 , -0.46000904]])"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.epochs =  1\n",
    "user_embedding, item_embedding, params = learn(net, train_loader, valid_loader)\n",
    "net.load_state_dict(params)\n",
    "user_embed = []\n",
    "for i in range(339):\n",
    "    user_embed.append(net.user_embed(t.tensor(i).cuda()).cpu().tolist())\n",
    "trained, non_trained = [], []\n",
    "for i in range(len(user_embed)):\n",
    "    if i in idx:\n",
    "        trained.append(user_embed[i])\n",
    "    else:\n",
    "        non_trained.append(user_embed[i])\n",
    "np.array(trained)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.57651317, -0.24181476, -0.50905973,  0.80809194, -0.32008168],\n       [ 0.62963688, -0.87307435, -1.15723062,  0.07763115,  0.77166176],\n       [ 0.96675229,  1.15178859,  0.12776124, -0.05298454, -1.41787803],\n       ...,\n       [-0.26286599, -0.82421356,  0.25917768, -0.80786818,  1.51441991],\n       [ 1.46801472, -1.27573347, -0.21419285, -2.75966334,  0.31739959],\n       [-0.54773873,  0.55409747,  0.78499675, -0.68874353, -1.36398768]])"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(non_trained)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 得出了结论，有相应的数据，对应的embedding才会被训练到"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "{190: 1,\n 165: 1,\n 89: 2,\n 195: 1,\n 36: 1,\n 71: 1,\n 59: 1,\n 282: 1,\n 149: 1,\n 330: 1,\n 241: 1,\n 139: 1,\n 248: 1,\n 189: 1,\n 106: 3,\n 21: 1,\n 326: 1,\n 303: 1,\n 219: 2,\n 223: 2,\n 143: 1,\n 283: 1,\n 50: 2,\n 265: 1,\n 94: 1,\n 44: 1,\n 323: 1,\n 233: 1,\n 276: 2,\n 191: 2,\n 161: 2,\n 178: 1,\n 306: 1,\n 255: 1,\n 194: 2,\n 77: 1,\n 222: 1,\n 65: 1,\n 337: 1,\n 209: 1,\n 235: 1,\n 56: 1,\n 289: 3,\n 61: 1,\n 116: 1,\n 284: 1,\n 293: 2,\n 208: 1,\n 328: 2,\n 100: 1,\n 279: 1,\n 7: 1,\n 196: 1,\n 215: 1,\n 102: 1,\n 88: 1,\n 299: 1,\n 230: 1,\n 234: 1,\n 83: 1,\n 275: 1,\n 32: 1,\n 318: 2,\n 80: 1,\n 253: 1,\n 101: 2,\n 270: 3,\n 124: 1,\n 52: 1,\n 333: 1,\n 200: 1,\n 313: 1,\n 9: 1,\n 90: 1,\n 26: 1,\n 127: 1,\n 66: 1,\n 42: 2,\n 31: 1,\n 39: 1,\n 136: 1,\n 251: 1,\n 316: 1,\n 184: 1,\n 62: 1,\n 245: 1,\n 43: 1,\n 331: 1,\n 177: 1,\n 315: 1,\n 281: 1,\n 216: 1,\n 76: 1,\n 335: 1,\n 325: 1,\n 291: 1,\n 198: 1,\n 288: 1,\n 249: 1,\n 213: 1,\n 312: 1,\n 261: 1,\n 262: 1,\n 155: 1,\n 29: 1,\n 207: 1,\n 290: 1,\n 206: 1,\n 158: 1}"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [190, 165,  89, 195,  36,  71,  59, 282, 149, 330, 241, 139, 248, 189,\n",
    "        106,  21, 326, 303, 219, 223, 143, 283,  50, 265,  94,  44, 106, 323,\n",
    "        233, 276, 191, 161, 178, 306, 255, 194,  77, 222,  65, 337, 209, 235,\n",
    "         56, 289, 194,  61, 116, 284, 293, 208, 328, 328, 100, 279,   7, 196,\n",
    "        215, 102,  88, 299, 191, 230, 234,  83, 275,  32, 318, 161,  80, 253,\n",
    "        101, 270, 124,  52, 333, 200, 313,   9,  90,  26, 127,  66,  42, 270,\n",
    "         31, 276,  39, 136, 251, 316, 184, 289,  62, 245,  43, 270, 331, 177,\n",
    "        101, 315, 281, 219, 216,  42, 223,  76, 335, 325, 291, 198, 288, 106,\n",
    "        293, 249,  50, 213, 312, 261, 318, 262, 289, 155,  89,  29, 207, 290,\n",
    "        206, 158]\n",
    "dic = {}\n",
    "for i in a:\n",
    "    if i not in dic:\n",
    "        dic[i] = 1\n",
    "    else:\n",
    "        dic[i] += 1\n",
    "dic"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
