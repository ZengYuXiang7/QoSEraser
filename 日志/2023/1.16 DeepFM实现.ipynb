{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import dgl as d\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from dgl.nn.pytorch import SAGEConv\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import *\n",
    "import pandas as pd\n",
    "\n",
    "t.set_default_tensor_type(t.FloatTensor)\n",
    "\n",
    "class DataTransformer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lamd = None\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "\n",
    "    def fit(self,X):\n",
    "        from scipy import stats\n",
    "        X, self.lamd = stats.boxcox(X)\n",
    "        self.min = X.min()\n",
    "        self.max = X.max()\n",
    "        X = (X-self.min) / (self.max - self.min)\n",
    "        return X\n",
    "\n",
    "    def inverse(self,X):\n",
    "        from scipy.special import inv_boxcox\n",
    "        X = X * (self.max - self.min) + self.min\n",
    "        X = inv_boxcox(X, self.lamd)\n",
    "        return X\n",
    "\n",
    "\n",
    "def getIPClass(ip):\n",
    "    try:\n",
    "        ips = ip.split('.')\n",
    "        ips = [int(ip) for ip in ips]\n",
    "        if 1 <= ips[0] <= 127:\n",
    "            return 1\n",
    "        if 128 <= ips[0] <= 191:\n",
    "            return 2\n",
    "        if 192 <= ips[0] <= 223:\n",
    "            return 3\n",
    "        if 224 <= ips[0] <= 239:\n",
    "            return 4\n",
    "        if 240 <= ips[0] <= 255:\n",
    "            return 5\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "class FeatureLookup():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__inner_id_counter = 0\n",
    "        self.__inner_bag = {}\n",
    "        self.__category = set()\n",
    "        self.__category_bags = {}\n",
    "        self.__inverse_map = {}\n",
    "\n",
    "    def register(self, category, value):\n",
    "        # 添加进入类别\n",
    "        self.__category.add(category)\n",
    "        # 如果类别不存在若无则，则新增一个类别子树\n",
    "        if category not in self.__category_bags:\n",
    "            self.__category_bags[category] = {}\n",
    "\n",
    "        # 如果值不在全局索引中，则创建之，id += 1\n",
    "        if value not in self.__inner_bag:\n",
    "            self.__inner_bag[value] = self.__inner_id_counter\n",
    "            self.__inverse_map[self.__inner_id_counter] = value\n",
    "            # 如果值不存在与类别子树，则创建之\n",
    "            if value not in self.__category_bags[category]:\n",
    "                self.__category_bags[category][value] = self.__inner_id_counter\n",
    "            self.__inner_id_counter += 1\n",
    "\n",
    "    def query_id(self, value):\n",
    "        # 返回索引id\n",
    "        return self.__inner_bag[value]\n",
    "\n",
    "    def query_value(self, id):\n",
    "        # 返回值\n",
    "        return self.__inverse_map[id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__inner_bag)\n",
    "\n",
    "def Metrics(realVec, estiVec):\n",
    "    realVec = np.array(realVec)\n",
    "    estiVec = np.array(estiVec)\n",
    "    absError = np.abs(estiVec - realVec)\n",
    "    mae = np.mean(absError)\n",
    "    nmae = mae / (np.sum(realVec) / absError.shape[0])\n",
    "    rmse = np.linalg.norm(absError) / np.sqrt(absError.shape[0])\n",
    "    relativeError = absError / realVec\n",
    "    mre = np.percentile(relativeError, 50)\n",
    "    npre = np.percentile(relativeError, 90)\n",
    "    return np.array([mae, nmae, rmse, mre, npre])\n",
    "\n",
    "class QoSFMDataset(t.utils.data.Dataset):\n",
    "    def __init__(self,lookup):\n",
    "        import time\n",
    "        self.lookup = lookup\n",
    "        # Load Dataset\n",
    "        print('Loading Dataset')\n",
    "        start = time.time()\n",
    "        self.wslist = pd.read_csv('./datasets/data/WSDREAM/原始数据/wslist.csv').to_numpy()\n",
    "        self.userlist = pd.read_csv('./datasets/data/WSDREAM/原始数据/userlist.csv').to_numpy()\n",
    "        self.rtMatrix = np.loadtxt('./datasets/data/WSDREAM/原始数据/rtMatrix.txt')\n",
    "        self.tpMatrix = np.loadtxt('./datasets/data/WSDREAM/原始数据/tpMatrix.txt')\n",
    "        self.rtTransformer = DataTransformer()\n",
    "        self.tpTransformer = DataTransformer()\n",
    "        self.recs = []\n",
    "        for i in tqdm(range(339)):\n",
    "            for j in range(5825):\n",
    "                if self.rtMatrix[i][j] <= 0 or self.rtMatrix[i][j] >= 19.9:\n",
    "                    continue\n",
    "                if self.tpMatrix[i][j] <= 0 or self.tpMatrix[i][j] >= 1000.0:\n",
    "                    continue\n",
    "                self.recs.append([i,j])\n",
    "        self.recs = np.array(self.recs)\n",
    "\n",
    "        self.rtMatrix[self.rtMatrix > 0] = self.rtTransformer.fit(self.rtMatrix[self.rtMatrix>0])\n",
    "        self.tpMatrix[self.tpMatrix > 0] = self.tpTransformer.fit(self.tpMatrix[self.tpMatrix>0])\n",
    "\n",
    "        p = np.random.permutation(len(self.recs))\n",
    "        self.recs = self.recs[p]\n",
    "        end = time.time()\n",
    "        print('Dataset Ready! Time=%.3fs'%(end-start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.recs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i,j = self.recs[idx]\n",
    "        uid = f'User{i}'\n",
    "        sid = f'Serv{j}'\n",
    "        ure, uas = self.userlist[i][2],self.userlist[i][4]\n",
    "        sre, sas, spr = self.wslist[j][5],self.wslist[j][7],self.wslist[j][3]\n",
    "\n",
    "        ure = f'URE_{ure}'\n",
    "        uas = f'UAS_{uas}'\n",
    "\n",
    "        sre = f'SRE_{sre}'\n",
    "        sas = f'SAS_{sas}'\n",
    "        spr = f'SPR_{spr}'\n",
    "\n",
    "        uid = self.lookup.query_id(uid)\n",
    "        sid = self.lookup.query_id(sid)\n",
    "        ure = self.lookup.query_id(ure)\n",
    "        uas = self.lookup.query_id(uas)\n",
    "        sre = self.lookup.query_id(sre)\n",
    "        sas = self.lookup.query_id(sas)\n",
    "        spr = self.lookup.query_id(spr)\n",
    "        rt = self.rtMatrix[i][j]\n",
    "        tp = self.tpMatrix[i][j]\n",
    "\n",
    "        return [uid,sid,ure,uas,sre,sas,spr], rt ,tp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# ====================================================#\n",
    "# Create Graph\n",
    "# ====================================================#\n",
    "\n",
    "graph = d.graph([])\n",
    "lookup = FeatureLookup()\n",
    "\n",
    "ulines = pd.read_csv('./datasets/data/WSDREAM/原始数据/userlist.csv').to_numpy()\n",
    "slines = pd.read_csv('./datasets/data/WSDREAM/原始数据/wslist.csv').to_numpy()\n",
    "\n",
    "\n",
    "for uid in range(339):\n",
    "    lookup.register('User', f'User{uid}')\n",
    "\n",
    "for sid in range(5825):\n",
    "    lookup.register('Serv', f'Serv{sid}')\n",
    "\n",
    "for ure in ulines[:, 2]:\n",
    "    lookup.register('URE', f'URE_{ure}')\n",
    "\n",
    "for uas in ulines[:, 4]:\n",
    "    lookup.register('UAS', f'UAS_{uas}')\n",
    "\n",
    "for spr in slines[:, 3]:\n",
    "    lookup.register('SPR', f'SPR_{spr}')\n",
    "\n",
    "for sre in slines[:, 5]:\n",
    "    lookup.register('SRE', f'SRE_{sre}')\n",
    "\n",
    "for sas in slines[:, 7]:\n",
    "    lookup.register('SAS', f'SAS_{sas}')\n",
    "\n",
    "graph.add_nodes(len(lookup))\n",
    "\n",
    "for line in ulines:\n",
    "    uid = line[0]\n",
    "    ure = line[2]\n",
    "    uas = line[4]\n",
    "    uid = f'User{uid}'\n",
    "    ure = f'URE_{ure}'\n",
    "    uas = f'UAS_{uas}'\n",
    "\n",
    "    uid = lookup.query_id(uid)\n",
    "    ure = lookup.query_id(ure)\n",
    "    if not graph.has_edges_between(uid,ure):\n",
    "        graph.add_edges(uid, ure)\n",
    "\n",
    "    uas = lookup.query_id(uas)\n",
    "    if not graph.has_edges_between(uid,uas):\n",
    "        graph.add_edges(uid, uas)\n",
    "\n",
    "    if not graph.has_edges_between(ure,uas):\n",
    "        graph.add_edges(ure, uas)\n",
    "\n",
    "for line in slines:\n",
    "    sid = line[0]\n",
    "    spr = line[3]\n",
    "    sre = line[5]\n",
    "    sas = line[7]\n",
    "\n",
    "    sid = f'Serv{sid}'\n",
    "    sre = f'SRE_{sre}'\n",
    "    spr = f'SPR_{spr}'\n",
    "    sas = f'SAS_{sas}'\n",
    "\n",
    "    sid = lookup.query_id(sid)\n",
    "    sre = lookup.query_id(sre)\n",
    "    if not graph.has_edges_between(sid,sre):\n",
    "        graph.add_edges(sid, sre)\n",
    "\n",
    "    sas = lookup.query_id(sas)\n",
    "    if not graph.has_edges_between(sid,sas):\n",
    "        graph.add_edges(sid, sas)\n",
    "\n",
    "    spr = lookup.query_id(spr)\n",
    "    if not graph.has_edges_between(sid,spr):\n",
    "        graph.add_edges(sid, spr)\n",
    "\n",
    "    if not graph.has_edges_between(sre,spr):\n",
    "        graph.add_edges(sre, spr)\n",
    "\n",
    "    if not graph.has_edges_between(sre,sas):\n",
    "        graph.add_edges(sre, sas)\n",
    "\n",
    "    if not graph.has_edges_between(spr,sas):\n",
    "        graph.add_edges(spr, sas)\n",
    "\n",
    "graph = d.add_self_loop(graph)\n",
    "graph = d.to_bidirected(graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:01<00:00, 222.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Ready! Time=3.974s\n"
     ]
    }
   ],
   "source": [
    "dataset = QoSFMDataset(lookup)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# ====================================================#\n",
    "# Create DataLoader\n",
    "# ====================================================#\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def get_splited_datasets(dataset,density,testsize=100000):\n",
    "    trainsize  = int(density * len(dataset))\n",
    "    trainset,testset = random_split(dataset,[trainsize, len(dataset)-trainsize])\n",
    "    testset,_ = random_split(testset,[testsize, len(testset)-testsize])\n",
    "    return trainset, testset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    idxs = []\n",
    "    rts = []\n",
    "    tps = []\n",
    "    for rec in batch:\n",
    "        idx,rt ,tp = rec\n",
    "        idxs +=[idx]\n",
    "        rts += [rt]\n",
    "        tps += [tp]\n",
    "\n",
    "    return t.tensor(idxs),t.tensor(rts),t.tensor(tps)\n",
    "\n",
    "\n",
    "class GraphSAGEConv(t.nn.Module):\n",
    "\n",
    "    def __init__(self,graph, dim, order=3):\n",
    "        super(GraphSAGEConv, self).__init__()\n",
    "        self.order = order\n",
    "        self.graph = graph\n",
    "        self.embedding = t.nn.Parameter(t.Tensor(self.graph.number_of_nodes(), dim)).cuda()\n",
    "        t.nn.init.kaiming_normal_(self.embedding, nonlinearity='relu')\n",
    "        self.graph.ndata['L0'] = self.embedding\n",
    "        self.layers = t.nn.ModuleList([SAGEConv(dim, dim, 'gcn') for _ in range(order)])\n",
    "        self.norms = t.nn.ModuleList([t.nn.BatchNorm1d(dim) for _ in range(order)])\n",
    "        self.acts = t.nn.ModuleList([t.nn.ReLU() for _ in range(order)])\n",
    "\n",
    "    def forward(self):\n",
    "        feats = self.graph.ndata['L0']\n",
    "        res = feats\n",
    "        last = feats\n",
    "        for i, (layer, norm, act) in enumerate(zip(self.layers, self.norms, self.acts)):\n",
    "            feats = layer(self.graph, feats).squeeze()\n",
    "            feats = norm(feats)\n",
    "            feats = act(feats)\n",
    "            last = feats\n",
    "            res = t.cat((feats, res), -1)\n",
    "        return res, feats\n",
    "\n",
    "\n",
    "class FM(t.nn.Module):\n",
    "    \"\"\"Factorization Machine models pairwise (order-2) feature interactions\n",
    "     without linear term and bias.\n",
    "      Input shape\n",
    "        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, 1)``.\n",
    "      References\n",
    "        - [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FM, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        fm_input = inputs\n",
    "        square_of_sum = t.pow(t.sum(fm_input, dim=1, keepdim=True), 2)\n",
    "        sum_of_square = t.sum(fm_input * fm_input, dim=1, keepdim=True)\n",
    "        cross_term = square_of_sum - sum_of_square\n",
    "        cross_term = 0.5 * t.sum(cross_term, dim=-1, keepdim=False)\n",
    "        return cross_term\n",
    "\n",
    "\n",
    "class DeepFM(t.nn.Module):\n",
    "    def __init__(self, graph, latent_dim, order=3):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.GraphEmbedding = GraphSAGEConv(graph, latent_dim, order=order)\n",
    "\n",
    "        self.FeatureWeights = t.nn.Embedding(graph.number_of_nodes(), 1)\n",
    "        t.nn.init.kaiming_normal_(self.FeatureWeights.weight)\n",
    "\n",
    "        self.Deep = t.nn.Sequential(\n",
    "            t.nn.Linear((order + 1) * 7 * latent_dim, 4 * latent_dim),\n",
    "            # t.nn.Linear(7*latent_dim,4*latent_dim),\n",
    "            t.nn.LayerNorm(4 * latent_dim),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Linear(4 * latent_dim, 2 * latent_dim),\n",
    "            t.nn.LayerNorm(2 * latent_dim),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Linear(2 * latent_dim, 1)\n",
    "        )\n",
    "        self.FM = FM()\n",
    "\n",
    "    def forward(self, Idx):\n",
    "\n",
    "        if t.cuda.is_available():\n",
    "            Idx = Idx.cuda()\n",
    "        bs = Idx.shape[0]\n",
    "\n",
    "        # Graph Spreading Embedding\n",
    "        embedding, feats = self.GraphEmbedding()\n",
    "\n",
    "        # One\n",
    "        one = self.FeatureWeights(Idx)\n",
    "        one = t.sum(one, 1)\n",
    "\n",
    "        # Two\n",
    "        feat_embeds = feats[Idx]\n",
    "        two = self.FM(feat_embeds)\n",
    "\n",
    "        # FM Output(LR)\n",
    "        yfm = (one + two).sigmoid().squeeze()\n",
    "\n",
    "        # Deep Part\n",
    "        din = t.reshape(embedding[Idx], (bs, -1))\n",
    "        ydnn = self.Deep(din).squeeze()\n",
    "\n",
    "        # Return\n",
    "        return (yfm + ydnn).sigmoid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def EvaluationOnce(graph,trainset,testset,order,dimension):\n",
    "    trainLoader = DataLoader(trainset, 256, shuffle=True, num_workers=6, pin_memory=True,collate_fn=collate_fn)\n",
    "    testLoader = DataLoader(testset, 256, shuffle=True,num_workers=6, pin_memory=True,collate_fn=collate_fn)\n",
    "    graph = graph.to(t.device('cuda'))\n",
    "    model = DeepFM(graph,dimension, order=order).cuda()\n",
    "    loss = t.nn.L1Loss().cuda()\n",
    "    lr = 8e-3\n",
    "    optimizer = t.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "    bestMAE = 2e9\n",
    "    for epoch in trange(30):\n",
    "        total_loss = 0\n",
    "        if epoch % 10 == 0 and epoch > 0:\n",
    "            lr /= 2\n",
    "            optimizer = t.optim.AdamW(model.parameters(),lr=lr, weight_decay=1e-3)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch in trainLoader:\n",
    "            optimizer.zero_grad()\n",
    "            idx, label, _ = batch\n",
    "            val = model(idx)\n",
    "            val = val.reshape(label.shape)\n",
    "            trainloss = loss(val, label.cuda())\n",
    "            trainloss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += trainloss\n",
    "\n",
    "        arr0 = np.zeros((5,))\n",
    "        model.eval()\n",
    "        for batch in testLoader:\n",
    "            idx, label, _ = batch\n",
    "            val = model(idx)\n",
    "            val = val.reshape(label.shape)\n",
    "            val, label = val, label.cuda()\n",
    "            val = val.cpu().detach().numpy()\n",
    "            label = label.cpu().detach().numpy()\n",
    "            val = dataset.rtTransformer.inverse(val)\n",
    "            label = dataset.rtTransformer.inverse(label)\n",
    "            arr0 += Metrics(val, label)\n",
    "\n",
    "        arr0 /= len(testLoader)\n",
    "\n",
    "        if arr0[0] <= bestMAE:\n",
    "            bestMAE = arr0[0]\n",
    "\n",
    "        # print(f'Epochs {epoch}: Loss={total_loss / len(trainLoader)}')\n",
    "        # print('Epochs %d: MAE:%.4f NMAE:%.4f RMSE:%.4f MRE:%.4f NPRE:%.4f' % (epoch, *arr0))\n",
    "\n",
    "    return bestMAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, ):\n",
    "        self.dataset = 'rt'\n",
    "        self.path = './datasets/data/WSDREAM/'\n",
    "        self.density = 0.10\n",
    "        self.processed = 0\n",
    "        self.part_type = 1\n",
    "        self.slices = 1\n",
    "        self.epochs = 30\n",
    "        self.retrain = 1\n",
    "        self.batch_size = 128"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from datasets.dataloader import get_dataloaders\n",
    "from datasets.dataset import load_data, create_graph, ShardedTensorDataset\n",
    "\n",
    "\n",
    "def Evaluation():\n",
    "    for density in [0.025,0.05,0.075,0.10]:\n",
    "        trainset, testset = get_splited_datasets(dataset,density,testsize=300000)\n",
    "        for dimension in [64, 128, 256]:\n",
    "            for order in [1, 2]:\n",
    "                bestMAE = EvaluationOnce(graph,trainset,testset,order,dimension)\n",
    "                print(f'Density={density}, Dim={dimension}, Order={order}, MAE = {bestMAE:.3f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.025, Dim=64, Order=1, MAE = 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:19<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.025, Dim=64, Order=2, MAE = 0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:05<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.025, Dim=128, Order=1, MAE = 0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:21<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.025, Dim=128, Order=2, MAE = 0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:07<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.025, Dim=256, Order=1, MAE = 0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:25<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.025, Dim=256, Order=2, MAE = 19.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:35<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.05, Dim=64, Order=1, MAE = 0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:53<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.05, Dim=64, Order=2, MAE = 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:29<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.05, Dim=128, Order=1, MAE = 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:57<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.05, Dim=128, Order=2, MAE = 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:45<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.05, Dim=256, Order=1, MAE = 19.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:09<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.05, Dim=256, Order=2, MAE = 0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:44<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.075, Dim=64, Order=1, MAE = 0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:21<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.075, Dim=64, Order=2, MAE = 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:56<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.075, Dim=128, Order=1, MAE = 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:25<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.075, Dim=128, Order=2, MAE = 0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:04<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.075, Dim=256, Order=1, MAE = 0.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:35<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.075, Dim=256, Order=2, MAE = 19.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:03<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.1, Dim=64, Order=1, MAE = 0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:33<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.1, Dim=64, Order=2, MAE = 0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:13<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.1, Dim=128, Order=1, MAE = 0.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:43<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.1, Dim=128, Order=2, MAE = 0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:32<00:00,  5.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.1, Dim=256, Order=1, MAE = 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:08<00:00,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density=0.1, Dim=256, Order=2, MAE = 0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Evaluation() # order = 2, dimension = 128\n",
    "# order = 1 , density = 2.5, dimension = 64, MAE = 0.471\n",
    "# order = 2 , density = 2.5, dimension = 64, MAE = 0.430\n",
    "# order = 1 , density = 2.5, dimension = 128, MAE = 0.421\n",
    "# order = 2 , density = 2.5, dimension = 128, MAE = 0.421"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
